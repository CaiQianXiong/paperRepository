---
alias:
å‘å¸ƒæ—¶é—´: 2021-01-01
å‡ºå“æ–¹: åä¸º
ä»·å€¼: â­â­
ç¯èŠ‚: ç²¾æ’
---

å…³é”®è¯:: #Reco/ç‰¹å¾äº¤äº’ 

---
# Enhancing Explicit and Implicit Feature Interactions via Information Sharing for Parallel Deep CTR Models
* è¦è§£å†³çš„é—®é¢˜ï¼š
  * ä¸€ä¸ªæ˜¯insufficent sharing
    * é’ˆå¯¹çš„æ˜¯DCNä¸­ï¼Œexplicit feature interactionéƒ¨åˆ†ä¸implicit feature interactionéƒ¨åˆ†åªåœ¨æœ€åæ‰èƒ½èåˆçš„é—®é¢˜ï¼ˆlate fusionï¼‰ã€‚åŸæ¥æ˜¯parallel structure, insufficient sharingã€‚
    * With late fusion, explicit and implicit feature interaction networks **do not share information in the intermediate hidden layers**, which **weakens** the interactive signals between each other and may easily lead to skewed gradients during the backward propagation
  * å¦ä¸€ä¸ªæ˜¯excessive sharing
    * å–‚å…¥cross layerä¸dnn layeréƒ½æ˜¯ç›¸åŒçš„embeddingæ‹¼æ¥ï¼Œä½œè€…è®¤ä¸ºä¸å¦¥ï¼Œå¯¹äºä¸åŒçš„feature interactionåº”è¯¥å–‚å…¥ä¸åŒçš„feature
    * å¯¹äºè¿™ä¸ªé—®é¢˜ï¼Œåˆ›æ–°æ€§æ¯”è¾ƒä½ï¼Œ~~ä¸è¿‡æ˜¯åŠ äº†LHUCè€Œå·²~~ï¼ˆè¿˜ä¸å¦‚lhucï¼Œæƒé‡æ˜¯ç›´æ¥å®šä¹‰çš„ä¼˜åŒ–å˜é‡ï¼Œè€Œä¸ä¼¼lhucé‚£æ ·è¿˜æœ‰gate inputï¼‰

* è§£å†³æ–¹æ¡ˆï¼Œæå‡ºEnhanced DCN
  * bridge moduleï¼Œenhance information sharing between explicit and implicit feature interaction
  * regularization module: learn discriminative feature distributions for different networks by a **field-wise gating** network in a soft selection manner.
  * åœ¨æ¯ä¸ªhidden layeræ—¶ï¼Œä¹ŸåŠ lhucæ¥ç­›é€‰è¾“å…¥ï¼Œlearn discriminative feature distributions for each hidden layer of the two networks.

* å¯èƒ½å­˜åœ¨çš„é—®é¢˜
  * ç”±äºcross layerå’Œdnn layerè¦sharingï¼Œå°±å¼ºåˆ¶è¦æ±‚äº†ä¸¤ä¸ªç»“æ„ä¸­çš„æ¯å±‚è¾“å‡ºéƒ½å¿…é¡»å…·å¤‡ç›¸åŒçš„å½¢çŠ¶ï¼Œå¯¹æ¨¡å‹ç»“æ„æœ‰ç‚¹ä¸çµæ´»
  * cross layeræœ‰ä¸€ä¸ªéå¸¸å¤§çš„ç¼ºç‚¹ï¼Œå°±æ˜¯ä¸èƒ½æ„å»ºé‡‘å­—å¡”é‚£æ ·çš„ç»“æ„ï¼Œæ¯å±‚çš„è¾“å‡ºéƒ½å’ŒåŸå§‹è¾“å…¥çš„ç»´åº¦æ˜¯ç›¸åŒçš„ï¼Œè€ŒåŸå§‹è¾“å…¥çš„ç»´åº¦å°±æ˜¯å„ä¸ªfield embeddingçš„æ‹¼æ¥ï¼Œå¦‚æœéƒ½æ¥å…¥æ˜¯ç›¸å½“å¤§çš„ã€‚è®¡ç®—èµ·æ¥æœ‰ç‚¹æ…¢ã€‚

## Explicit vs. Implicit ä¸¤å¤§ç±»ç»“æ„

* stacked: Models with stacked structure first perform explicit feature interaction modeling over the embedding layer and then stack an implicit component (normally DNN) to extract high-level feature interactions successivelyã€‚è¿DIN/DIENä¹Ÿç®—stacked (transformerä¸Šå†å åŠ dnn)
* parallel: FMã€DCNä¹‹ç±»çš„

![image.png | 600](assets/image-20211227150237-m2l4dmv.png)

## Bridge Module

late fusionæœ‰ä¸¤å¤§ç¼ºç‚¹ï¼š

* The late fusion strategy fails to capture the correlation between two parallel networks in the intermediate layers, weakening the interactive signals between explicit and implicit feature interaction.
* Moreover, **the lengthy updating progress in each sub-networks may lead to skewed gradients during the backward propagation**

æ‰€è°“bridge moduleå°±æ˜¯cross layerä¸dnn layerçš„æ¯å±‚ä¹‹åï¼Œå°±é©¬ä¸Šfusionä¸€ä¸‹ã€‚$f_l=f(x_l,h_l)$, where ğ‘“ (Â·) is a pre-defined interaction function that takes two vector as input and **outputs a vector with the same dimension**. fusionå‡½æ•°å¯ä»¥æ˜¯

* element-wise add
* **element-wise multiplication**ã€‚æ ¹æ®ä½œè€…çš„å®éªŒï¼Œ**æ­¤ç§æ–¹å¼æ•ˆæœæœ€å¥½**ã€‚
* concatenate+fc, $f_ğ‘™ = ReLU(w_ğ‘™^T [x_ğ‘™ , h_ğ‘™ ] + b_ğ‘™ )$
* æ‹¿cross layer outputä¸dnn layer outputåšä¸€ä¸ªself attention

## Regulation Module

è¿˜ä¸å¦‚lhucï¼Œç›´æ¥å°†å„field embeddingçš„æƒé‡å®šä¹‰æˆå¾…ä¼˜åŒ–å˜é‡ï¼Œç”Ÿå­¦å‡ºæ¥ã€‚è€Œä¸ä¼¼lhucï¼Œèµ·ç è¿˜æœ‰gate inputï¼Œä¹Ÿå°±æ˜¯æƒé‡è¦éšè¾“å…¥è€Œå˜åŒ–ã€‚

è‡³äºåœ¨å„hidden outputä¸­ä¹Ÿå¼•å…¥regularizationï¼Œæˆ‘åªèƒ½è¯´æœ‰ç‚¹å¼ºè¯å¤ºç†ï¼Œâ€œNote that the cross network in DCN is actually a linear transformation of $x_0$. In other words, field information still exists in the fused representation of the bridge module.â€ã€‚cross layerä¸­çš„ç¡®ä¹Ÿè¿˜èƒ½ä¿æŒfieldçš„åˆ’åˆ†ï¼Œé‚£ä¹ˆdnnä¹Ÿèƒ½å—ï¼Ÿ