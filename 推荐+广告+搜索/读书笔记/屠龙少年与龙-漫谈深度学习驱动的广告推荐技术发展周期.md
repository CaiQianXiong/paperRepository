---
alias:
发布时间: 2021-08-09
出品方: 阿里妈妈
价值: ⭐⭐⭐⭐⭐
---

环节:: 
关键词:: 实战经验

---

# [屠龙少年与龙：漫谈深度学习驱动的广告推荐技术发展周期](https://zhuanlan.zhihu.com/p/398041971) #TODO 

工业级深度学习1.0达到顶峰的几个标志：

> 1）搭积木式的模型架构演进，其边际收益越来越低；
>
> 2）深度模型进入数据饥饿阶段，希望进一步通过10倍、100倍的数据量来填充既有模型容量（model capacity），从而提升精度；
>
> 3） 大部分新的大型算法优化和改进，都需要工程系统架构配套进行巨大的升级改造
>


## 召回

现有召回的问题

> 1）召回通道越积越多，维护的代价极大；
>
> 2）==单通道覆盖的流量比例往往都不大==，据我所知普遍低于30%，从而导致==任一通道的技术升级对大盘的影响都被稀释==，花80分力气带来20分收益（负向2/8现象）；
>
> 3）==通道之间缺乏协同性，不同通道之间召回结果的overlap较大==，召回技术缺乏整体迭代的方法论。
>

历史原因，阿里展示广告之前的召回技术也存在以上的痛点，导致我们单点的技术厚度非常强（TDM系列技术），但体系性发展空间受限。对此，我给出的解法是：

> 1）全力推进model-based召回技术研发，投入重兵推进内核的召回算法创新，尽力砍掉小众琐碎的规则式召回通道，让整个召回技术收敛成最多2-3个算法簇，覆盖的流量占比超过80%，形成正向的2/8现象；
>
> 2）在模型簇召回技术的基础上建设==多召回通道联合建模==的算法，通过learning的方法构建==通道之间的协同通信==，在固定的召回quota下最大化召回集合的多样性；
>
> 3）从算力的视角思考召回系统，构建更强大的系统能力，使得召回的quota提升一个数量级以上。
>


### TDM

* [TDM 1.0解读](https://www.zhihu.com/question/362190044/answer/970781462)
* [TDM 2.0解读](https://zhuanlan.zhihu.com/p/85883448)
* [TDM 3.0解读](http://www.360doc.com/content/20/0904/22/7673502_934020904.shtml)

然而TDM技术也有其固有的不足：

* 首先是整个系统比较重，不论是训练系统还是在线serving系统，带来的挑战是**TDM只能训练得动短短几天的样本（例如，我们典型的TDM模型只用了一天的样本）**，丧失了对长周期信号的捕捉能力；
* 其次TDM中item/ad是tree的叶子节点，这导致了TDM建模的时候对item侧的**很多side information难以利用上**

  * 因为只有leaf node才有side information，非叶节点是抽象的，不对应任何实体item，当然不可能有side information
  * 非叶节点的side information能不能填0? 可能不太好吧，有点在数据中引入bias的味道
* 最后，TDM的算力消耗跟效果的tradeoff不太好balance，使得模型的复杂度还是显著受限。

### 二向箔

为了解决TDM的缺点，发展出了最新的**低精度复杂模型全库召回技术**，“二向箔”。

* 我形象地把TDM技术看成**模型、索引/系统、算力**三个自由度都打开的全库召回技术，它的天花板足够高，但略重，导致进一步迭代的技术债有点高；
* 而向量化全库召回技术则相反，它通过向量化的范式，把系统和算力的消耗控制在了极低的水平，技术体系非常的轻便，可以容纳和叠加很多新的技术，如GNN等，但天花板有限；
* 二向箔技术居于中间，**目标是将系统这个维度积分掉**，建立“**模型精度和算力消耗**”这两个自由度（维度）的可控平衡；它沿用暴力扫全库的系统实现思路，实现一个既灵活可迭代、同时又能够在给定的算力约束下支持任意复杂的信号（突破TDM在item侧缺信号的弱点）、任意复杂的模型（突破向量式双塔模型表达能力弱的限制）的全库召回技术。

作者所谓的算力tradeoff，在模型侧，实际上就是指"Hammer压缩算法"[^1]。在特征输入和DNN每个神经元后面都加上一个gate，训练的过程中就能知道哪些特征和哪些链接可以删除掉。


### 近线计算

包括TDM、二向箔在内的全库召回技术都是在线**实时**计算的技术体系。如果用户兴趣变化的时效性不强，还有另外一条可行路径，采用近线计算的方式摆脱实时计算对latency和算力的约束，空间换时间，

* 采用任意复杂的模型、以低频率更新的节奏（如每天/周执行一次）==提前计算好每一个用户在全库空间中的召回结果，将其存储在分布式内存（如memcache）中，在线用户访问的时候直接读取缓存的召回结果就行==。
* 另外，这里的计算消耗又可以利用低频率更新模式下算力可以削峰填谷的优势，从而在总算力基本不增的情况下完成任意复杂度的全库召回近线计算任务。
* 当然，对于广告场景而言，远不止这么简单，因为广告的价格、以及广告主圈选的定向条件限制等可以随时发生变化，因此还需要一个通路来执行==delta更新==，这样对这套近线计算系统的要求就比较高。

参考："Truncation-Free Matching System for Display Advertising at Aliba..."[^2](主要不是设计来解决全库召回的近线计算问题，只是提供了一种可行的架构解)


### 多通道协同建模

在主流量被model-based召回算法覆盖后，采用联合建模的方式，强化通道之间的通信与协同

> 1）loss函数包括两部分，一部分是任意单一模型在label域的loss（简称label loss）；第二部分是对模型召回集合的loss（简称set loss）。只不过实操中大部分的召回模型都还是point-wise的形式，==因此set loss需要能被分解到任意一个候选item/ad上进行计算==（label loss天然满足这一点）；
>
> 2）set loss的设计是多通道协同的关键，比如一种straight forward的、我们实践过的方案是定义==set的diversity（多样性）==，进一步我们把这个==diversity近似为embedding向量之间的距离==，这样可以直接带来给定召回集合quota下diversity的提升，背后实际相当于==让不同模型的召回集合强行推向了互补的空间==。
>


## 粗排

无非就是COLD，而cold中所谓“把算力当作优化目标”，无非就是用一些压缩算法，随着主目标的学习自动学习出哪些特征和哪些链接可以被删除掉。