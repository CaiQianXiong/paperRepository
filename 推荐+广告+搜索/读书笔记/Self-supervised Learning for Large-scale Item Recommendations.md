---
alias:
å‘å¸ƒæ—¶é—´: 2021-02-25
å‡ºå“æ–¹: Google
ä»·å€¼: â­â­â­â­â­
---

ç¯èŠ‚:: å¬å›
å…³é”®è¯:: #Reco/åŒå¡”æ¨¡å‹ #ML/è‡ªç›‘ç£å­¦ä¹  

---

# Self-supervised Learning for Large-scale Item Recommendations 

## æ¦‚è¿°

* Long-tail itemsçš„labeléå¸¸sparse
* ==ç›®æ ‡æ˜¯ç”¨å¯¹æ¯”å­¦ä¹ çš„æ–¹æ³•ï¼Œå°†long-tail item embeddingå­¦ä¹ å¥½==

## **Self-Supervised Learning (SSL)åŸºç¡€**

**The basic idea is to enhance training data with various data augmentations, and supervised tasks to predict or reconstitute the original examples as auxiliary tasks.**ã€‚NLPä¸­çš„bertè¿™ç§mask and predict missing wordå°±ç®—æ˜¯SSL

### SSLçš„ä¼˜ç‚¹ï¼Œ

* ä¸€æ˜¯ä¸å¿…äººä¸ºæ”¶é›†labelï¼Œ
* äºŒæ˜¯autonomous discovery of good semantic representations by **exploiting the internal relationship of input features**.
* ä¹Ÿä½œä¸ºä¸€ç§æ›´å¥½çš„**regularization**. è¿™é‡Œæ˜¯æ‰€è°“çš„**spread-out regularization**, promoting large instance separations in the embedding space.

### SSL Framework

![|500](https://api2.mubu.com/v3/document_image/a12f6c2d-8944-4ee4-b8fa-c207a0d39ea8-11457030.jpg)

1. augment data by masking input information;
2. encode each pair of augmented examples by a two-tower DNN; **å°½ç®¡passä¸¤ä¸ªå¡”ï¼Œä½†æ˜¯å¡”çš„å‚æ•°å¯ä»¥æ˜¯å…±äº«çš„**(ä¹Ÿå¯ä»¥ä¸å…±äº«)ï¼Œ**ç±»ä¼¼SimCLR**
3. apply a contrastive loss (i.e., **auxiliary loss**) to learn representations of augmented data. ä¹Ÿå°±æ˜¯å°½ç®¡augmentedä¹‹åï¼Œä¸¤æ¡æ ·æœ¬é•¿å¾—å¯èƒ½å·®åˆ«å¾ˆå¤§ï¼Œä½†æ˜¯åˆ†åˆ«ç»è¿‡toweråå¾—åˆ°çš„embeddingåº”è¯¥æ˜¯éå¸¸ç›¸ä¼¼çš„ã€‚ï¼ˆå…¬å¼ä¸­çš„Næ˜¯batchä¸­çš„æ ·æœ¬æ•°ï¼‰

![|700](https://api2.mubu.com/v3/document_image/d0a1a968-a7f4-4db2-8e60-6cd85b9ee4fe-11457030.jpg)


## åŸºäºSSLçš„åŒå¡”å¬å›

![|1000](https://api2.mubu.com/v3/document_image/c72ccd4b-b78b-409c-a597-0119c9671179-11457030.jpg)

### item data augmentation

#### ä¼ ç»Ÿæ–¹æ³•

Given a set of item features, the key idea is to create two augmented examples by **masking** part of the information.

* **Masking**. Apply a masking pattern on the set of item features.

  * we could randomly split the feature set into two disjoint subsets into the two augmented examples. We call this method **Random Feature Masking (RFM)**.
  * ä½†æ˜¯ï¼Œéšæœºmaskingï¼Œä¼šå¯¼è‡´æ¨¡å‹ä¼šåˆ©ç”¨â€œå¤šä¸ªç›¸å…³ç‰¹å¾çš„ä¸å®Œæ•´â€è€Œè½»æ˜“åšå‡ºåˆ¤æ–­ã€‚ä¸ºæ­¤æœ¬æ–‡æå‡º[CFM](siyuan://blocks/20211114095148-cy97sl5)ã€‚
* **Dropout**. For categorical features with **multiple values**, we drop out each value with a certain probability.

#### **Correlated Feature Masking (CFM)** 

we further explore the feature correlations when creating masking patterns.

1. pre-calculateä¸¤ä¸ªcategorical feature Vi,Vjçš„mutual informationï¼Œä¹Ÿå°±æ˜¯åœ¨Vi, Vjè¿™ä¸¤ä¸ªvocabulary setä¸­æ¯å¯¹ç‰¹å¾å‡ºç°çš„æ¦‚ç‡

    ![|500](https://api2.mubu.com/v3/document_image/56d755ba-1279-4927-8716-665baf3971b8-11457030.jpg)
2. by first uniformly sample a seed feature $ğ‘“_{ğ‘ ğ‘’ğ‘’ğ‘‘}$ from all the available features ğ¹ = { ğ‘“ 1 , ..., ğ‘“ ğ‘˜ },
3. and then select the top-n most correlated features ğ¹ ğ‘ = { ğ‘“ ğ‘,1 , ..., ğ‘“ ğ‘,ğ‘› } according to their mutual information with ğ‘“ ğ‘ ğ‘’ğ‘’ğ‘‘ .
4. The final ğ¹ ğ‘š will be the union of the seed and set of correlated features, i.e., ğ¹ ğ‘š = { ğ‘“ ğ‘ ğ‘’ğ‘’ğ‘‘ , ğ‘“ ğ‘,1 , ..., ğ‘“ ğ‘,ğ‘› }.

    We choose ğ‘› = âŒŠğ‘˜/2âŒ‹ so that the masked and retained set of features have roughly the same size.

### ç¦»çº¿è®­ç»ƒ

![|500](https://api2.mubu.com/v3/document_image/d75fa0c9-0b73-453b-836e-0351d648d247-11457030.jpg)

#### ä¸»è¦ä»»åŠ¡

experimentä¸­çš„main taskæ˜¯ä¸€ä¸ªitem-to-item retrievalé—®é¢˜ 

* Note that we only collect positive examples, i.e., ğ‘¥ ğ‘ğ‘ğ‘›ğ‘‘ğ‘–ğ‘‘ğ‘ğ‘¡ğ‘’ is an installed app from the landing page of ğ‘¥ ğ‘ ğ‘’ğ‘’ğ‘‘ . **All the impressed recommended apps with no installs are all ignored** since we consider them more like weak positives instead of negatives for building retrieval models.

  ![|500](https://api2.mubu.com/v3/document_image/ff80c376-95ef-4c23-ae38-96ac25615908-11457030.jpg)
* æ‰€ä»¥ä¸€ä¸ªbatchåªåŒ…å«Nä¸ªæ­£æ ·æœ¬ï¼Œbatch softmaxå¦‚ä¸‹ã€‚é‡‡ç”¨äº†batchä¸­å…¶ä»–itemä½œä¸ºè´Ÿæ ·æœ¬æ”¾å…¥åˆ†æ¯ï¼Œè€Œä¸”è¿˜æœ‰æ¸©åº¦ç³»æ•°ã€‚

#### è¾…åŠ©ä»»åŠ¡

**main taskä¸­çš„itemä¸contrastive taskä¸­çš„itemæ¥è‡ªä¸åŒåˆ†å¸ƒ** #Reco/æ ·æœ¬ç­–ç•¥

* main taskä¸­çš„itemæ¥è‡ªæ›å…‰æ•°æ®ï¼Œç»å¤§éƒ¨åˆ†æ˜¯**å¤´éƒ¨item**
* è¿™ç¯‡æ–‡ç« çš„ç›®çš„å°±æ˜¯ä¸ºäº†è§£å†³long-tail itemçš„é—®é¢˜ï¼Œå› æ­¤ssl taskä¸­çš„itemä¸èƒ½ä¹Ÿæ¥è‡ªlog. =="we sample items uniformly from the corpus for $L_{SSL}$"==
* æ³¨æ„ï¼Œmain taskå’ŒSSL taskçš„æ­£æ ·æœ¬itemåº”è¯¥é‡‡ç”¨ä¸åŒçš„åˆ†å¸ƒï¼Œæ‰èƒ½å–å¾—debiasçš„æ•ˆæœã€‚â€œ==In practice, we find using the heterogeneous distributions for main and ssl tasks is critical for SSL to achieve superior performance.==â€œ

#### å…±åŒè®­ç»ƒ

* contrastive lossä½œä¸ºè¾…åŠ©losså’Œmain taskä¸€åŒè®­ç»ƒã€‚
* å› ä¸º[ä¸»è¾…ä»»åŠ¡é—´itemçš„ä¸åŒåˆ†å¸ƒ](siyuan://blocks/20211114095148-0u7yjqo)ï¼Œé‚£ä¹ˆauxiliary taskæ˜¯å¦‚ä½•è¾…åŠ©main taskçš„å‘¢ï¼Ÿç­”æ¡ˆæ˜¯==å‚æ•°å…±äº«==

  * â€œIn order to make SSL facilitate the supervised learning task, we ==share the embedding table== of sparse features for both neural encoderâ€
  * å¦‚åŸºäºSSLçš„åŒå¡”å¬å›æ‰€ç¤ºï¼ŒThe whole item tower (in red) is ==shared== with the supervised task. ä½†æ˜¯ä¹Ÿä¸æ˜¯ç»å¯¹ï¼Œ"**Depending on the technique for data augmentation (â„, ğ‘” ), the MLPs of H and G could also be fully or partially shared.**"

#### å¾…è§£å†³çš„é—®é¢˜

* æœ¬æ–‡ç”¨çš„æ˜¯main task+ssl task jointly trainçš„schema å…±åŒè®­ç»ƒï¼Œè€Œécv/nlpä¸­é‚£æ ·pre-training+fine tuningé‚£æ ·çš„è®­ç»ƒèŒƒå¼
* we plan to investigate how different training schemes impact the model quality. One direction is to **first pre-train** on SSL task to learn query and item representations and **fine-tune** on primary supervised tasks.