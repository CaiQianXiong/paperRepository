---
alias: ETA
å‘å¸ƒæ—¶é—´: 2021-08-10
å‡ºå“æ–¹: é˜¿é‡Œå¦ˆå¦ˆ
ä»·å€¼: â­â­â­â­
ç¯èŠ‚: ç²¾æ’
---
å…³é”®è¯:: #Reco/ç”¨æˆ·è¡Œä¸ºåºåˆ— 

---

# End-to-End User Behavior Retrieval in Click-Through Rate Prediction Model

## æ€è·¯
- ä¹‹å‰æ–¹æ³•çš„ç¼ºç‚¹
	- poolingçš„æ–¹æ³•å°±æ˜¯æ²¡æœ‰â€œåƒç‰©åƒé¢â€ï¼Œè€Œä¸”poolingå°†æ‰€æœ‰historyéƒ½åŒ…å«åœ¨å†…ï¼Œæœ‰å™ªå£°
	- DINæ˜¯â€œåƒç‰©åƒé¢â€ï¼Œä½†æ˜¯ä¸èƒ½å¤„ç†long historyï¼Œå› ä¸ºattentionçš„æ—¶é—´å¤æ‚åº¦æ˜¯O(L\*B\*d)
	- MIMNå°†å»ºæ¨¡user interestä¸ä¸»æ¨¡å‹åˆ†ç¦»ï¼ŒMIMN can handle long-term user behavior sequence by decouplng the user interest modeling with the rest of CTR task. **The user interest vector is updated offline in an asynchronous way whenever a new behavior is observed**. 
	- SIMæ–¹æ³•çš„ç¼ºç‚¹åœ¨äºï¼Œä¸¤ä¸ªé˜¶æ®µä¹‹é—´æœ‰<span style="color:orange;font-weight:bold">information gap</span>ğŸ’¡ğŸ’¡ğŸ’¡
		- ç›®æ ‡ä¸ä¸€è‡´
			- the target of retrieval part should keep the same with the whole CTR model. Only in this way can the top-k retrieved items contribute the most to the CTR model
			- ç”¨categoryæ¥è¿›è¡Œhard searchæ˜¾ç„¶å±äºâ€œç›®æ ‡ä¸ä¸€è‡´â€çš„æƒ…å†µã€‚use category to select items from user behavior sequence which share the same attribute with target candidate item, which is <span style="color:orange;font-weight:bold">divergent with the target of CTR model</span>
		- æ›´æ–°ä¸ä¸€è‡´
			- <span style="color:crimson;font-weight:bold">SIM also tried to building an offline inverted index based on the pre-trained embedding</span>.  ^g3gjgh
			- <span style="color:red;font-weight:bold"></span>During <span style="color:crimson;font-weight:bold">training and inference</span>, the model can search the top-K â€œsimilarâ€ items. <span style="color:crimson;font-weight:bold">train/inferæ—¶éƒ½è¦è®¿é—®è¿™ä¸ªç”±offline pre-trained embeddingå»ºç«‹çš„inverted index</span>ã€‚ ^fiyiqe
			- But most of the CTR model is in online learning paradigm and the embedding is updated continuously. 
			- <span style="color:crimson;font-weight:bold">Thus the pre-trained embedding in offline inverted index is outdated compared with the embedding in online CTR model</span>
		- æ€»è€Œè¨€ä¹‹ä¸€å¥è¯ï¼Œæ²¡æœ‰ä½¿ç”¨ctr modelä¹‹ä¸­çš„embeddingï¼Œå¯¼è‡´retrievalä¸ctr modelè„±èŠ‚ã€‚"<span style="color:crimson;font-weight:bold">However, the inputs they used for building the index are attribute information (e.g., category) or pre-trained embedding of items, which are different with the embedding used in CTR model</span>"

``` ad-note
title: ETAæ€è·¯çš„æ¼”å˜

- æ‰€ä»¥ï¼Œé—®é¢˜çš„å…³é”®åœ¨äºï¼Œç”¨item embeddingæ¥æœç´¢user long history
- é€ä¸€dotè®¡ç®—ç›¸ä¼¼æ€§ï¼Œæ—¶é—´å¤æ‚åº¦=O(L\*B\*d)ï¼ŒL=history length, B=batch_size, d=embedding dimension
- SIMçš„ä½œæ³•æ˜¯ï¼Œå°†item embeddingç¦»çº¿å»ºç«‹ç´¢å¼•ï¼Œæ—¶é—´å¤æ‚åº¦æ˜¯O(log(L)\*B\*d)ï¼Œä½†æ˜¯è®¡ç®—ç›¸ä¼¼æ€§çš„æ–¹æ³•è¿˜æ˜¯dotã€‚
	- ä»˜å‡ºçš„ä»£ä»·å°±æ˜¯indexæ˜¯ç¦»çº¿å»ºç«‹çš„ï¼Œä¸å¯èƒ½ä¸ctr modelæ‰€ä½¿ç”¨çš„item embeddingä¿æŒä¸€è‡´
- ETAæå‡ºçš„æ–¹æ³•æ˜¯ï¼Œæ›´æ¢æ£€éªŒembeddingç›¸ä¼¼æ€§çš„æ–¹æ³•ï¼Œå°†æ—¶é—´å¤æ‚åº¦å˜æˆO(L\*B\*1)ğŸ’¡ğŸ’¡ğŸ’¡
	- ä¼˜ç‚¹æ˜¯æ— éœ€å†ç¦»çº¿å»ºç«‹ç´¢å¼•ï¼Œtarget itemåœ¨long historyä¸­æœç´¢ç›¸ä¼¼itemï¼Œä¸main ctr modelå…±äº«ä¸€å¥—embedding
	- ğŸ’¡ğŸ’¡ğŸ’¡The reduction of complexity helps us removing the offline auxiliary model and conducting **real-time retrieval** during training and serving procedure
```

## SimHash
- SimHash function takes the embedding vector of an item as input and generates its binary fingerprint
- Each d-dimensional vector is converted to a m-length integer binary vector (i.e., 0 or 1).  
	- In real ctr model, <span style="color:blue;font-weight:bold">d=128, m=4</span>.
- ![[Pasted image 20220406204346.png | 500]]
	- not sensitive to the selection each rotation â€œhashing functionâ€. Any fixed random hash vectors are enough
	- ç»“æœæ˜¯ä¸€ä¸ªbinary vector,  which can further be decoded using an integer to save storage cost and to speed up the following hamming distance calculation.
- ![[Pasted image 20220406204534.png | 500]]
	- we can observe that nearby embedding vectors can get the same hashing signature with high probability
- In other words, ==the inner product between two vectors can be replaced by hamming distance==.
	- The hamming distance for two integers is defined as the number of different bits positions at which the corresponding bits are different. 
	- To get the hamming distance of two m-bit numbers, we first conduct XOR and then count the number of bits in 1
	- E.g., 11011001 âŠ• 10011101 = 01000100. Since, this contains two 1s, the Hamming distance, d(11011001, 10011101) = 2
	- <span style="color:orange;font-weight:bold">If we define the multiplication as the atomic operation, then the complexity of hamming distance for two m-digit numbers is O(1)</span>. 
		- we can use ~~log(m)-bits integer~~(â“â“â“why not m bits 1 or 0) to represent the signature vector because each element is either 1 or 0. 
		- This can greatly reduce the cost of memory and can speed up the calculation of hamming distance. 
		- The calculation time of two integers can be conducted in O(1) time complexity and can be neglected.

## åŸºäºSimHashçš„Top-K retrieval
- Top-K retrievalç”±inner productæ—¶çš„O(L\*B\*d)ç®€åŒ–æˆO(L\*B\*1)
	- ~~æ¯ä¸ªå‘é‡çš„m-bit hash fingerprintå¯æå‰è®¡ç®—å¥½ä¿å­˜è¿›embedding tableä¸­ï¼Œæ— éœ€é‡å¤è®¡ç®—~~è®­ç»ƒçš„æ—¶å€™ï¼Œembeddingå˜æ¢é¢‘ç¹ï¼Œæ²¡æœ‰ç¼“å­˜çš„å¿…è¦
	- æˆ‘è§‰å¾—è¿™ä¹ˆæ¯”è¾ƒæ˜¯æ²¡æ„ä¹‰çš„ï¼Œå¤§å®¶éƒ½çŸ¥é“O(L\*B\*d)æ˜¯æ²¡æœ‰ä¸Šçº¿å¯èƒ½çš„ã€‚æ‰€ä»¥ä¹‹å‰SIMå³ä½¿ç”¨äº†dot productæ¥æ£€ç´¢ï¼Œä¹Ÿ[[Search-based User Interest Modeling with Lifelong Sequential Behavior Data for Click-Through Rate Prediction#^qrlc73 | è‚¯å®šä¸ä¼šæ˜¯linear time complexity,å¿…ç„¶æ˜¯sub-linear complexity]] ^j7y0or
	- æ­£ç¡®çš„æ¯”è¾ƒåº”è¯¥æ˜¯ï¼Œ<span style="color:orange;font-weight:bold">ç”±SIMçš„O(log(L)*B*d)-->å˜æˆäº†ETAçš„O(L*B*1)</span>

- <span style="color:orange;font-weight:bold">Ensure that the top-k nearest keys to query in each iteration are selected using the latest embedding of CTR model seamlessly</span>
	- <span style="color:orange;font-weight:bold">å³ä½¿æ˜¯åœ¨è®­ç»ƒæ¯ä¸ªbatchæ—¶</span>ï¼Œmain ctr modelæ›´æ–°äº†item embeddingï¼Œæ°¸è¿œç”¨æœ€æ–°çš„item embeddingæ¥retrieval top-k similar history items w.r.t target item

- æ³¨æ„ï¼ŒETAç”¨hamming distanceåªæ˜¯æ”¹å–„äº†GSUéƒ¨åˆ†ï¼Œæ˜¯ç”¨ä¸€ç§æ›´ç®€å•çš„æ–¹æ³•æ¥ä»long historyä¸­ç­›é€‰è¿‡æ»¤å‡ºä¸target itemç›¸ä¼¼çš„historical item
	- ç­›é€‰åï¼Œè¿˜æ˜¯ç»è¿‡ESUï¼Œæ‹¿target itemä¸retrieved top-k long historical itemåštarget attention

- It is noteworthy that the hashed **fingerprints can be stored in an embedding table with the model each time the SimHash function is conducted**. 
	- During the inference time, only embedding lookup is needed and its complexity is negligible.
	- ä¹Ÿå°±æ˜¯æ¯æ¬¡å‘infer serveræ‰“ä¸€å¥—embeddingï¼Œå°±æŠŠæ¯ä¸ªembeddingçš„fingerprintæ‰“è¿‡å»ï¼Œæ²¡å¿…è¦åå¤è®¡ç®—


## æ•´ä½“ç»“æ„
- ![[Pasted image 20220406212723.png | 500]]

- å·¥ä¸šçº§åœºæ™¯ä¸‹çš„æ•°æ®è§„æ¨¡
	- The recent 48 behaviors are selected as short-term user behavior sequence and 
	- the recent 1024 behaviors are selected as long-term user behavior sequence
	- è¿™ä¸ªè§„æ¨¡ä¸SIMå®£ç§°çš„ä¸‡çº§åˆ«çš„history lengthï¼Œåˆå°‘äº†ä¸€ä¸ªæ•°é‡çº§
	- [[End-to-End User Behavior Retrieval in Click-Through Rate Prediction Model#^j7y0or |æ­£å¦‚æˆ‘ä¹‹å‰æ‰€è¯´çš„]]ï¼Œæ­£ç¡®çš„ç¬”æ³•æ˜¯SIMçš„O(log(L)\*B\*d)-->å˜æˆäº†ETAçš„O(L\*B\*1)ã€‚å“ªä¸ªæ•ˆç‡æ›´é«˜ï¼Œè¿˜çœŸä¸ä¸€å®šã€‚