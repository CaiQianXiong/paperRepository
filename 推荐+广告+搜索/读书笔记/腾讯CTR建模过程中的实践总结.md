---
alias: 
发布时间: 2021-10-18
出品方: 腾讯
价值: ⭐⭐⭐⭐⭐
环节: 精排
---
关键词:: 实战经验, 在线学习

---

# [腾讯CTR建模过程中的实践总结](cubox://card?id=ff808081808324e001808a4a94e65530)

## Serving
- 线上预测的时候，是从redis获取特征，发往tf.serving

- 离线模型更新部分
	- 特征计算：运用 Spark/Flink 例行化计算离线/实时特征，**保存到 redis 中以供线上服务读取**（Lambda架构），同时保存到 TDW 表中备份 
	- 样本拼接：DSP 将线上服务中每个请求的特征上报到 TDBank，并落库 TDW。并每天根据曝光、点击上报日志，**以 request_id 为 key 拼接样本**，并将样本出库到 HDFS
	- 模型训练：每天定时开始检查 HDFS 上的数据，数据成功出库后触发模型训练，训练完成后以 timestamp 作为“版本号”保存到指定路径中
	- 模型部署：模型服务采用 Docker+tf.Serving 的模式，其中 Docker 容器和 IDC 训练机同时挂在同一个 CFS 路径。**所以只需要将新模型 copy 到指定的 CFS 路径下，tf.Serving 即可自动读取版本号最大（即 timestamp 最大）的最新版本的模型进行预测服务**

## 特征

- 特征预处理
	- 原来的方法，无非就是min-max归一化、normalization、截断
		- 标准化和归一化，都不很好处理long-tail distribution的数据
		- 截断会损失信息
		- 标准化和归一化，都是要依赖离线计算的min/max/mean/var这样的统计数据的
			- <span style="color:red;font-weight:bold">问题在于这些统计数据如何更新</span> ❓
			- 更新太频繁了，这样特征也会出现较大波动，比如hash后映射到其他embedding
			- 更新不频繁，也有stale的问题
	- <span style="color:orange;font-weight:bold">腾讯的新方法，不再标准化，直接取log</span> 💡
		- ![[Pasted image 20220506153250.png | 300]]
		- 这样做的目的是尽可能不损失区分度的情况下，对该特征进行压缩，避免模型无法收敛的情况。
		- 由于对于不同日期的数据，不论其分布如何，都统一采取同样的预处理方式，所以不会出现模型更新后，分布不稳定的情况。
		- 经过多次离线实验，采用该变换公式解决收敛性和稳定性问题的同时，并未导致 AUC 降低，真是一个好办法！

- 也采用了人工交叉特征
	- 30+个“用户交叉特征”。比如：“该用户在该游戏上的历史点击率”、“该用户在该媒体上的历史点击数”等
	- 80+个“用户属性标签交叉特征”。比如“该职业用户在该游戏上的历史点击率”、“该年龄段用户在该广告模板上的历史点击率”等

- 使用了离线根据word2vec训练好的素材embedding
	- 不明白为什么不直接end-to-end学习？？

## 模型

- 采用了embedding$\times$ weight的方式喂入模型

- 腾讯的模型路线：DeepFM$\rightarrow$ AutoInt$\rightarrow$ DCN V2
	- DCN V2也剔除一些特征不交叉，我猜也是因为DCN只交叉不压缩，代价太大。
	- <span style="color:cyan;font-weight:bold">Wide部分始终保留</span>

- 使用了GateNet，也就是我们的LHUC给输入特征不同权重
	- 出发角度是<span style="color:orange;font-weight:bold">为了降低特征之间的共线性</span>
	- 目前来看，还不知道这个gate的输入是什么，是所有feature吗？
	- “既然深度学习模型本身的学习机制就可以让无关特征的影响降低，从而起到变量筛选的作用，为什么还要单独一个 Gate Layer 来给变量赋权呢？答案就是：“假设空间太大”，一个全连接层的参数量与前后两层节点数的乘积成正比，参数量很大，不容易学习。**相比之下 Gate Layer 中的参数量就少了很多，假设空间更小，更容易学习**”

- 序列建模
	- 每类序列，同时使用了max-pooling和din target attention再拼接
	- ![[Pasted image 20220506155211.png | 300]]

- 多任务建模
	- 是click和play两类任务
	- 视频播放标签分为：
		- “未播放到 75%”、
		- “播放至 75%到 100%之间”、
		- “完成播放”、
		- “其他”这四个标签，其中“其他”主要表示非视频类曝光
	- 难道play任务是按multi-class建模？

## 校准

- 模型的偏差主要有以下 4 个来源
	- 训练样本偏差。建议压根就不要对负样本进行down-sampling
	- 预测时出现训练中未出现过的new feature
		- 方法1：特征中除了ID类特征，也要加入泛化特征
		- 方法2：在线学习
	- 数据迁移：只能在线学习、及时更新。
	- 模型收敛到局部最优解
		- 模型假设空间越大，越容易收敛到局部最优解，
		- 所以我们在进行模型版本迭代时，<span style="color:pink;font-weight:bold">尽可能不要以引入大量参数为代价，去追求细微的效果提升</span>❓❓❓
		- 这短期看是可以取得更好的效果，但长期看其实是给自己挖坑

## 在线学习 #价值/💡 

- 技术难题：
	- 在线学习的样本是实时获取的，所以实时样本无法和离线样本一样进行全局 shuffle。这使每一时刻下的实时样本分布与全局整体分布有很大差异。
	- <span style="color:red;font-weight:bold">简单增量更新，很容易产生灾难性遗忘（Catastrophic Forgetting）</span>，“狗熊掰棒子”。

### 方案1：冻结参数
- 我们基于以下三条假设提出参数冻结的方案：
	- Embedding与Cross结构的作用不同
		- Embedding 主要学习 User/Item 的表征；
		- 复杂的交叉结构（如 FC、Cross 等结构），主要学习用户与 Item 的交叉信息（如“男性喜欢玩枪战游戏”） 
	-  线上分布的变化，
		- 主要体现在 Item/User 分布的变化（新建广告/新接入媒体等）；
		- 而不是用户偏好的变化（比如男性用户上午喜欢打 CF，下午突然集体改玩爱消除） 
	- 在离线模型中，模型已经用大量的数据，比较好的训练了交叉结构

- 方法：我们在实时训练时，
	- <span style="color:orange;font-weight:bold">冻结模型的 FC 层、Cross 层等交叉结构的参数</span>，令其不进行更新，
	- <span style="color:orange;font-weight:bold">仅使用实时样本更新 Embedding 层的参数</span>。

- 缺点：
	- 牺牲了模型的学习能力

### 方案2：回放样本参与训练

- 冻结参数后，还是发现模型的效果不稳定
	- 比如：实验组，上午好

- 方法：<span style="color:orange;font-weight:bold">增加“样本回放”</span>参与实时训练
	- 过去一天当前小时以后的样本（YYYYMM(DD-1)HH \~ YYYYMM(DD-1)23）进行采样，与实时样本按照一定比例混合
	- 比如现在是下午1点，那实时样本都是1点左右的样本，而1点之前的样本模型已经训练过了，但是模型不知道1点之后的数据会是什么样子。
	- 所以我们就从昨天的样本中选取1点之后的样本加入进去。

### 方案3：蒸馏学习
- 以上两个方案的缺点：
	- 冻结参数，牺牲模型学习能力
	- 回放样本，损害了样本和模型的实时性

- 蒸馏的方法
	- 离线模型做Teacher（<span style="color:pink;font-weight:bold">离线模型是天级更新的吗？</span>）
	- 实时模型做Student
	- 让student不要离teacher太远

- 从文中来看，要解决“灾难性遗忘”问题，只使用“蒸馏学习”一个方案就行了
	- ![[Pasted image 20220506162134.png | 500]]

## 评估

### 离线AUC

- 作者提出了一个Base AUC的概念
	- 说明从 0.5->0.78 这么多的 AUC 提升，其实对于 CTR 的提升没有半毛钱直接作用
	- 因为模型只能对多个请求之间进行排序，而点击率提升需要模型对一个请求内部的多个 Item 进行排序。
	- 这种情况模型的主要作用应该是降低了偏差，我们称这时的 AUC 为 Base AUC。
	- 这部分主要是由User侧特征支撑起来的

- 达到了 Base AUC 之后，
	- AUC 再想继续提升，难度会很大，但是对 CTR 的贡献会非常明显，可能 AUC 提升 0.0001 就可以给 CTR 带来收益了。
	- 因为这时的提升主要是靠交叉特征，以及模型深度挖掘用户偏好带来的，这部分提升可以直接作用在一个 PV 内部。

- 使用GAUC，甚至使用Session AUC
	- 固然能够将关注点聚焦于PV内部的排序，而非排序不同的PV
	- 但是对于广告这种正样本太少的场景，反而会因为没有足够多的数据而无法统计

- 作者的观点是：<span style="color:orange;font-weight:bold">不使用GAUC，只使用AUC还是有用的</span>
	- 实际上只要 AUC 突破了一个门槛（即类似前面提到的 Base AUC），将 User 特征和 Scene 特征压榨干净，后续的 AUC 提升与 CTR 的提升是有很强的正相关的。
	- 所以我们大可放心继续使用 AUC 这个指标，只是在项目初期要清楚，前期的 AUC 提升主要效果是降 bias，而不是提升 CTR。

###  AB实验

#### 按设备分流
- 如果按照设备分流，通常需要先做 AA 实验，
	- 确保 AB 两组没有天然的差异性
	- 而且这个差异性可能是随时间变化的，可能工作日的时候两组差异小，周末两组差异大。
	- 所以设备分流实验中，这个因素的影响通常是不可忽略的。

- <span style="color:crimson;font-weight:bold">如果用户量足够大，是不是就可以抹平两组间的天然差异？</span> #价值/💡 
	- 答案是：<span style="color:crimson;font-weight:bold">理论如此，但是所需要的用户量会比预想的大</span>。
	- 举一个极端的例子，
		- 在广告中如果要做 ROI 的 AB 实验，由于付费行为本身<span style="color:cyan;font-weight:bold">非常稀疏</span>，且付费金额分布极其偏态（少数几个用户可能付费几十万，绝大多数付费只是首充），
		- 即使你广告大盘有 1 个亿的设备数，真正经过竞价、曝光、点击、转化后可能只剩几千个，再算上付费的可能就几十个，
		- 而这几十个里面可能只有一两个付费超过 1000 的大 R。
	- 也就是说，<span style="color:orange;font-weight:bold">虽然总体用户数很多，但是真正“有影响力的关键用户”会少很多。大盘用户量需要足够大到足以使“关键用户”足够多，才能抹平 AB 两组的差异</span>，这通常比人们直观感觉中的量级要大。

#### 按请求分流
- 好处是 AB 两组绝对不会存在差异性（除非代码有 BUG），省去了 AA 实验的步骤

- 但是有些研究用户长期行为的实验（比如品牌实验），
	- 要求用户需要长期被分到同一个组中，
	- 就不适用请求分流，必须用设备分流。

#### 辛普森悖论
- 如果实验组每一天的 CTR 都更高，就说明实验组更好么？答案是：不一定！
- 设想这样一种情况，
	- 如果实验组模型对某个本来点击率就很高高的 Item（比如一个很火的新游戏，很好看的素材等等）产生了高估，那实验组中这个 Item（游戏/素材）的占比就会更高。
	- 那实验组的整体点击率就会更高。
	- 这并不是因为模型排序排的更准，而是模型更倾向于把“曝光机会”分配给优质的 Item❓❓❓
- 其实，我不觉得以上实验有什么问题，能够将优质内容排在前面，不也是模型能力的体现吗？以上问题的现象，<span style="color:orange;font-weight:bold">只要对模型结果划分更细的group进行分析就行了</span>。
