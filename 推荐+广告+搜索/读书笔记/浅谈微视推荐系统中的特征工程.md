
---
alias:
发布时间: 
出品方: 腾讯
价值: ⭐⭐⭐⭐
---

环节:: 
关键词:: #ML/特征工程

---

# [浅谈微视推荐系统中的特征工程](https://mp.weixin.qq.com/s/EgiSIJCRfiRLKwHUC1m46A)

## A. 特征提取

### 1. 1.数值特征

例如用户对不同类目下视频的兴趣分,或者是计数,例如一个视频被播放了多少次、被点赞、转发以及评论了多少次等

#### a) 分桶

但是如果不同视频的播放次数跨越不同的数量级,则很难发挥想要的作用。
离散化之后的特征对于异常数据也具有很强的鲁棒性。

##### (1) 分桶方式
- 等距分桶,每个桶的值域是固定的,这种方式适用于样本分布较为均匀的情况;
- 等频分桶,即使得每个桶里数据一样多,这种方式可以保证每个桶有相同的样本数,但也会出现特征值差异非常大的样本被放在一个桶中的情况;
- 模型分桶,

##### (2) 需要注意
需要注意的是:
- 要使得桶内的属性取值变化对样本标签的影响基本在一个不大的范围,即不能出现单个分桶的内部,样本标签输出变化很大的情况;
- 使每个桶内都有足够的样本,如果桶内样本太少,则随机性太大, 不具有统计意义上的说服力;
- 每个桶内的样本尽量分布均匀。

#### b) 2)截断
有时精度太高可能只是噪声,并不具备太多的信
对于⻓尾的数据,可以先进行对数缩放,再进行精度截断

#### c) 3)缺失值处理
- 可以选择补一个值,
- 将缺失作为一种信息进行编码输入模型让其进行学习
- <font color="red">使用模型预测缺失值</font>

#### d) 4) 特征交叉
特征交叉可以表示特征之间的相互作用,有助于表示非线性关系,增强对问题的刻画,
- 内积
- 笛卡积
![](assets/220226101808_clip_image002.jpg)

#### e) 5)标准化与缩放
将其转化为无量纲的纯数值,使得不同单位或量级的特征之间具有可比性,对于利用梯度下降来训练模型参数的算法,有助于提升模型的收敛速度
- z-score 标准化
- 对数缩放,对数缩放对于处理⻓尾分布且取值为正数的数值变量非常有效,可以压缩数据范围,将⻓尾变为短尾,像`log2`和` log10`转换在微视中也都有使用,是一种方差稳定的变换

#### f) 6)数据平滑与消偏 #价值/⭐⭐⭐⭐ 
很多统计类特征、比率特征。如果直接使用,比如由于不同 item 的下发量是不同的
如果对于一个新上线的商品,其曝光为 0,点击量也为 0,此时这件商品的 CTR 应该设为 0 还是赋一个初始值?初始值设 0 是可以的,但不太合理。

##### ⻉叶斯平滑
⻉叶斯平滑的思想是给 CTR 预设一个经验初始值,再通过当前的点击量和曝光量来修正这个初始值。如果某商品的点击量和曝光量都是 0,那么该商品的 CTR 就是这个经验初始值;如果商品 A 和商品 B 的曝光量差别很大,那么可以通过这个经验初始值来修正

 beta 分布可以看做是对点击率的一个先验知识,我们可以根据观测来修改我们的先验,所以⻉叶斯平滑就是估计 Beta 分布中的参数 α 和 β,其中 C 和 I 是点击次数和曝光量。实际应用时根据历史数据得到的 α 和β 可以帮助确定平滑参数的大致范围,防止设置参数时偏离过大。

![ | 150](assets/220226101808_clip_image004.jpg)

##### 威尔逊区间平滑 #TODO 
威尔逊区间法是一种基于二项分布的计算方法,综合考虑评论数与好评率,平滑样本量对评价的影响
- 我们可以计算出 p 的置信区间。置信区间实际就是进行可信度的修正,弥补样本量过小的影响
- p 表示样本的naive好评率,n 表示样本的大小,z 表示对应某个置信水平的 z 统计量
![|500](assets/220226101808_clip_image006.jpg)

##### debias 消偏
- 我们可以把曝光量进行分段,同一个曝光量级的指标进行比较
- 也可以用该 item 所属类目统计量的平均值进行平滑处理。
- 对于outlier较多的数据,使用更加健壮的处理方法,比如使用中位数而不是均值,基于分位数而不是方差
- 短视频业务上较短或较⻓的视频在播放完成度上存在天然的差距,
	- 我们按视频本身⻓度离散,观看时⻓做<font color="orange">分位数</font>处理,同时做威尔逊置信区间平滑,
	- 使得各视频时⻓段播放完成度相对可比,避免出现打分因视频⻓度严重倾斜的情况。
- 短视频 app 的投稿数量大,对于⻓尾的视频和类目都是需要做平滑处理的

比如不同类目或者不同时⻓区间下的完播率、平均播放时⻓等,考虑到冷热⻔类目以及⻓短视频在统计量上本身存在明显的差异,平滑之后我们会用统计量均值进行消偏,这也相当于有一个对热⻔视频降权,对⻓视频提权的作用。

#### h) 8)多维度定义
有些特征可以结合多个属性或者统计量来定义。比如用户的活跃度特征可以从周/月登录次数、日播放时⻓、日播放个数、平均完播率等维度联合定义

#### i) 9)根据目标定制
我们可以根据不同目标正负样本的定义,分别为每个单目标模型构造正样本率特征
类似我6步位构建用户画像中的“[[刀功：谈推荐系统特征工程中的几个高级技巧#^1cf2c5 | 动作类型]]”维度。

### 2. 2.类别特征

#### a) 1)独热编码
#### b) 2)散列编码
特征哈希法的目标就是是把原始的高维特征向量压缩成较低维特征向量
代价：
- 通过哈希转换后学习到的模型变得很难检验,我们很难对训练出的模型参数做出合理解释。
- 另一个问题是它会把多个原始特征哈希到相同的位置上,出现哈希 collision 现象,但实际实验表明这种 collision 对算法的精度影响很小。

#### c) 3)打分排名编码 #价值/💡 
- 分别对用户一、二级类目的top1~top10 兴趣进行 one-hot,利用打分的排名对类别特征进行编码,强化兴趣打分排名的信号,且这种方式对于异常点较为不敏感;
- 比如用户活跃度较高的前topn 类目和不活跃度较高的前 topn 类目也可按次序排名作为离散特征。

#### d) 4)异常值处理
分箱离散化,都可以较好的减轻离群点的影响。

#### e) 5)类别特征之间交叉组合

视频类别与标签之间的组合特征

#### f) 6)类别特征和数值特征之间交叉组合
类别特征某个具体类别中计算一些统计量。例如用户对不同类目视频的完播率、平均播放时⻓,不同用户群体的互动指标等利用数值特征对类别特征进行处理
- 一二级类目的曝光次数 cross 快划次数的组合特征。比如分析某个用户的样本发现类似王者荣耀_31_31 的组合,即我们的推荐系统给这个用户曝光了 31 个王者荣耀的视频,但是每个都快速划过了
- 类目曝光次数 cross 一些统计量

### 3. 3.Embedding 特征

#### a) 1)视频 embedding
视频 embedding 分为基于内容的 embedding 和基于行为的 embedding,前者使用视频的标题、封面、图像,音频等视频自身属性信息,通过 nlp、图像视觉等技术获得 embedding,后者是基于用户与视频的交互行为数据获得

- 像airbnb那样用group embedding代替单个embedding
	- 取一段时间内同属性视频的平均 embedding 作为这个属性的 embedding 特征。这样当有新的视频进入到推荐库时,可以计算出新视频的视频属性 embedding。这样做的好处是在同一个语义空间做运算,排序模型不需要再重新学习 embedding 的空间分布
- 实际使用中我们采用增量式skip-gram 模型学习视频的 embedding,使用推荐库最新资源线上实时训练,将新入库的视频加入到模型中做增量式学习。
	- 但是，==一定要保证在同一个特征空间内==

#### b) 2)user embedding
- 另外建一个user embedding模型。最后把训练好的 DNN 模型最后一层隐层输出作为 user embedding。类似于粗排embedding当成特征喂入精排
- 将一段时间内用户点击过的视频的平均 embedding 作为该用户的 embedding 特征,
	- 当然这里的“平均”可以是简单的算术平均,也可以是根据视频的热度和时间属性等进行加权平均或者尝试用 RNN 替换掉平均操作
- 有时单个用户行为序列太稀疏了,无法直接训练,一般可以先对用户做聚类再训练。

#### c) 3)作者 embedding 
可以取作者近一个月内发布视频的平均 embedding,作为该作者的 embedding 特征

### 4. 4.context 特征
请求时间、用户手机品牌、手机型号、操作系统、当前网络状态(3g/4g/wifi)、用户渠道等实时属性特征以及之间的 cross 特征。

### 5. 5.session 特征
- session的划分
	- 固定行为数窗口,例如最近 100 条行为
	- 固定时间窗口,例如最近 3 天里
	- 连续行为窗口,例如用户 1 次打开 app 到关闭 app 期间
- 在获取到用户的 session 数据后,可以直接将 session 里对应的 item id 序列作为特征,或者是 session 内的类别统计数据

## B. 特征选择

### 1. 1.过滤式(Filtering)
- 覆盖率： 覆盖率很小的特征对模型的预测效果作用不大,可以剔除。
- 比如说某个特征方差接近于 0,说明不同样本在这个特征上基本没有什么差异
- Pearson 相关系数。
-  可以使用皮尔森卡方检验。卡方统计量取值越大,特征相关性越高。
- 互信息越大则表明两个变量相关性越高,互信息为 0 时,两个变量相互独立。

### 2. 2.封装式(Wrapping)
- 完全搜索;基于贪心的启发式搜索(前向/后向搜索等);随机搜索(模拟退火、遗传算法等)
- 缺点是需要对每一组特征子集训练一个模型,计算复杂度高。

### 3. 3.嵌入式(Embedding)
嵌入式方法将特征选择本身作为组成部分嵌入到学习算法里,速度快,效果好,
- 使用带正则惩罚项的模型,比如 L1 正则化
- 重要的特征更有可能出现在分裂较早的节点,作为分裂节点的次数也越多。因此,可以基于树模型中特征出现次数等指标对特征重要性进行排序。

## C. 特征重要性分析

### 1. 单特征AUC

对每个单特征训练模型,计算每个特征的 auc 或 gauc,并对其进行排名,精度越高表示该特征重要程度越高。
这个方法需要训练多个模型,效率较低

### 2. 预测时随机打乱顺序
特征值随机打乱。随机打乱验证集中某一特征变量的值,使用训好的模型进行预测,精度损失越多,说明该特征对于预测结果的影响越大,可以按照精度损失的多少对特征重要性进行排序。这个方法比随机取值更科学,保证了与原始特征分布是一致的

