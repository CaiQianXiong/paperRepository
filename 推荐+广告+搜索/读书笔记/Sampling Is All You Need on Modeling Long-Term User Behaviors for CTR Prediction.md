---
alias: SDIM
å‘å¸ƒæ—¶é—´: 2022-05-20
å‡ºå“æ–¹: ç¾å›¢
ä»·å€¼: â­â­â­â­â­
ç¯èŠ‚: ç²¾æ’
---
å…³é”®è¯:: #Reco/ç”¨æˆ·è¡Œä¸ºåºåˆ— 
URL:: [zotero](zotero://open-pdf/0_SUVNN46U/1)

---

# Sampling Is All You Need on Modeling Long-Term User Behaviors for CTR Prediction

## ä¸ETAçš„åŒºåˆ«ä¸è”ç³»

- å»¶ç»­çš„æ˜¯é˜¿é‡Œ[[End-to-End User Behavior Retrieval in Click-Through Rate Prediction Model|ETA]]çš„æ€è·¯
	- åœ¨çº¿æ ¹æ®target itemåŠ¨æ€æå–ç”¨æˆ·é•¿æœŸåºåˆ—ä¸­çš„å…³é”®å­åºåˆ—
	- é¿å…åƒSIM hard or softé‚£æ ·ï¼Œéœ€è¦ç¦»çº¿å»ºç«‹ç´¢å¼•ï¼Œå¸¦æ¥å»ºæ¨¡ç›®æ ‡ä¸æ›´æ–°é¢‘ç¹ä¸Šçš„gap
	- ç”¨çš„æ–¹æ³•ä¹Ÿå¾ˆç±»ä¼¼ï¼Œéƒ½æ˜¯ç”¨simhash

- ä¸ETAçš„åŒºåˆ«ï¼Œåœ¨äºå°†user historical itemä¸target iteméƒ½ç”¨simhashè·å¾—signatureåï¼Œå¦‚ä½•åˆ©ç”¨signature
	- ETAæ˜¯åœ¨hash signatureä¸Šç”¨hamming distanceæ¥è®¡ç®—è·ç¦»ï¼Œå–ä»£attentionï¼Œæ‰¾åˆ°ä¸target itemæœ€ç›¸ä¼¼çš„historical item
	- SDIMæ˜¯ç”¨hash signatureç›´æ¥å½“æˆkeyå»æŸ¥æ‰¾ï¼Œæ‰¾åˆ°ä¸target itemå…·æœ‰ç›¸åŒhash signatureçš„historical item

- èƒ½å¤Ÿç”¨hash signatureå½“keyç›´æ¥æŸ¥æ‰¾çš„åŸç†åœ¨äº
	- simhashä¸æ˜¯çåšçš„ï¼Œè€Œæ˜¯æ ¹æ®embeddingçš„å†…å®¹è¿›è¡Œçš„ï¼Œä¸¤ä¸ªembeddingå¾—åˆ°ç›¸åŒçš„simhashï¼Œåªèƒ½è¯´æ˜åŸæ¥ä¸¤ä¸ªembeddingä¹Ÿæ˜¯ç›¸ä¼¼çš„
	- å› æ­¤ï¼Œç”¨simhash signatureå½“keyå»æ£€ç´¢ï¼Œsimhash signatureå†²çªçš„æ¦‚ç‡å°±å–å†³äºtarget item embeddingä¸æŸä¸ªhistorical item embeddingçš„ç›¸ä¼¼ç¨‹åº¦

- å¦å¤–éœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒETAæ˜¯ä¸¤æ­¥èµ°ï¼Œè€ŒSDIMæ˜¯ä¸€æ­¥åˆ°ä½
	- ETAç”¨simhashåªæ˜¯åœ¨SIMç¬¬1æ­¥çš„GSUé˜¶æ®µï¼Œç”¨ä¸€ç§æ›´ç®€å•çš„æ–¹å¼æ¥ä»long historyä¸­ç­›é€‰è¿‡æ»¤å‡ºä¸target itemç›¸å…³çš„historical itemã€‚ä½†æ˜¯å¦‚ä½•å°†ç­›é€‰å‡ºçš„å¤šä¸ªlong historical itemèšåˆæˆä¸€ä¸ªå‘é‡ï¼Œè¿˜æ˜¯å¸¸è§„çš„multi-head target attention
	- DSIMæ˜¯ä¸€æ­¥åˆ°ä½ï¼Œhash signature collideçš„æ¦‚ç‡å°±ç›¸å½“äºtarget attentionï¼Œç”¨hash sigatureæ£€ç´¢çš„è¿‡ç¨‹ç›¸å½“äºåœ¨æ•´ä¸ªlong history sequenceä¸Šåštarget attention


## ä½œæ³•

### ç¬¬1æ­¥ï¼šç”Ÿæˆhash signature
- ç¬¬1æ­¥ï¼Œwe sample from multiple hash functions to generate hash signatures of the target item and each item in user behavior sequence. 

- LSH & SimHash
	- LSHæœ‰locality-preservingå±æ€§ï¼Œç›¸ä¼¼å‘é‡ï¼Œæœ‰è¾ƒå¤§æ¦‚ç‡collide
	- simhashæ˜¯LSHçš„ä¸€ç§å®ç°ã€‚The random projection scheme (SimHash) is an efficient implementation of LSH. 
	- The basic idea of SimHash is to sample a random projection (defined by a normal unit vector r) as hash function to hash input vectors into two axes (+1 or -1).
	- ![[Pasted image 20220710104657.png |300]]
	- ä¸€æ¬¡æ€§ç”Ÿæˆmä¸ªhash signature, ![[Pasted image 20220710104759.png |300]]

- ![[Pasted image 20220710095813.png |400]] ^5886dd
	- æ‰€è°“çš„(m,$\tau$)-simhashï¼Œ
		- må°±æ˜¯ç”¨å¤šå°‘ä¸ªhash functionï¼Œä¸€ä¸ªembeddingç”¨äº†mä¸ªhash functionï¼Œå°±å¾—åˆ°m-bits
		- è€Œ$\tau$å°±æ˜¯åœ¨m-bitså½“ä¸­ï¼Œä»¥$\tau$ä¸ªbitä¸ºå•ä½ï¼Œç»„æˆ$\frac{m}{\tau}$ä¸ªsignature
		- ä¸€ä¸ªembeddingï¼Œå°±ä¼šè¢«åˆ†å…¥å¯¹åº”çš„$\frac{m}{\tau}$ä¸ªbucketä¸­
		- åˆ†é…åˆ°ä¸€ä¸ªbucketä¸­çš„å¤šä¸ªembeddingè¦èšåˆæˆä¸€ä¸ªå‘é‡ï¼Œå›¾ä¸­`norm(s0+s1)`å°±ä»£è¡¨ç›¸åŠ ï¼Œå†L2-normalization

### ç¬¬2æ­¥ï¼šç›´æ¥æ ¹æ®hash signatureæå–

- we directly gather behavior items that share the same hash signature with the target item to form the user interest
	- ![[Pasted image 20220710112652.png |300]]
	- *Instead of retrieving top-ğ‘˜ similar items using a certain metric like ETA*
	- The intrinsic idea behind our method is to approximate the softmax distribution of user interest with LSH collision probability

- The outputs of ğ‘š/ğœ hash signatures are averaged for a low variance estimation of user interest.
	- ![[Pasted image 20220710101031.png |500]]


## ç­‰ä»·äºtarget attention
- We show theoretically that this simple sampling-based method produces ==very similar attention patterns as softmax-based target attention== and achieves consistent model performance, while being much more time-efficient. 
	- our method behaviors like ==computing attention directly on the original long sequence==

- æ‹¿æŸä¸€ä¸ª$\tau$-bitå»æ£€ç´¢çš„è¿‡ç¨‹å°±ç›¸å½“äºå¦‚ä¸‹çš„target attention
	- ![[Pasted image 20220710105402.png |400]]
	- the width parameter ğœ plays a role in controlling the strength of the model on paying more attention to more similar items. **As ğœ increases, encourages the model to pay more attention to more similar items**.
	- å¦‚æœ$\tau$éå¸¸éå¸¸é•¿ï¼Œå®é™…ä¸Šé™¤étarget itemä¸æŸä¸ªhistorical itemå®Œå…¨ä¸€è‡´ï¼Œå¦åˆ™å¾ˆå°‘å¯èƒ½å†²æ’ä¸Šã€‚æ‰€ä»¥$\tau$è¶Šå¤§ï¼Œattentionæ—¶å¯¹â€œç›¸ä¼¼â€çš„è¦æ±‚è¶Šé«˜ï¼Œç›¸ä¼¼æ€§å·®ä¸€ç‚¹å°±ä¸attendäº†ã€‚
	- $\tau=0$ï¼Œå°±ç›¸å½“äºå¯¹æ‰€æœ‰historical itemåšmean poolingäº†

## æ¶æ„

- ![[Pasted image 20220710112857.png |500]]
	- åªæœ‰å¯¹short historyæ‰åštarget attention
	- å¯¹äºé•¿æœŸå†å²ï¼Œä»æ ¹æ®target itemçš„hash signatureæå–å‡ºæ¥çš„å‘é‡ï¼Œå°±å·²ç»æ˜¯attentionè¿‡äº†ï¼ˆ**sampled-based attention**ï¼‰ï¼Œæ— é¡»å†åƒSIM ESUé‚£æ ·å†åšattention

- ![[Pasted image 20220710094219.png |500]]
	- è®­ç»ƒçš„æ—¶å€™ï¼Œåˆåœ¨ä¸€èµ·è®­ç»ƒï¼Œå› ä¸ºuser interest modeling partä¹Ÿæ²¡æœ‰ä»€ä¹ˆå‚æ•°è¦è®­ç»ƒ
	- éƒ¨ç½²çš„æ—¶å€™ï¼Œè¦behavior sequence encoding serverä¸ctr serveråˆ†å¼€éƒ¨ç½²
	- åˆ†å¼€éƒ¨ç½²çš„å¥½å¤„ï¼ŒWe put the BSE Server before the CTR Server and **compute it in parallel with the retrieval module**ï¼Œç›¸å½“äºæå–ä¸€ä¸ªæ–°ç‰¹å¾
		- **item embeddingå¯¹åº”çš„hash signatureæ˜¯å¯ä»¥ç¼“å­˜çš„**
		- æˆ–è€…æ¯æ¬¡å¢é‡æ›´æ–°embeddingæ—¶ï¼Œå°±æŠŠæœ€æ–°çš„hash signatureè®¡ç®—å¥½
		- æœ‰äº†ç¼“å­˜ï¼Œé¿å…é‡å¤è®¡ç®—item embeddingçš„hash signatureï¼ŒBSEçš„å·¥ä½œåªç›¸å½“äºå°†long historical seuqnceåˆ†æ¡¶
	- For each request, we need to *transmit bucket representations from the BSE server to the CTR server*. the size of this vector is 8KB and the transmission cost is about 1ms.

## æ€§èƒ½åˆ†æ
- Batch Sizeä¸€èˆ¬éƒ½æ˜¯1000çº§æ°´å¹³
- dä¸€èˆ¬æ˜¯100çº§æ°´å¹³
- m=48
- $\tau=3$

- æ— è®ºä¸€ä¸ªrequesté‡Œé¢æœ‰å¤šå°‘candidate itemï¼Œ[[Sampling Is All You Need on Modeling Long-Term User Behaviors for CTR Prediction#^5886dd |å°†user historical sequenceå…ˆsimhashå†åˆ†æ¡¶]]ï¼Œåªéœ€è¦åšä¸€é
	- The most time-consuming part of SDIM is the multi-round hashing of the behavior sequence, i.e., transform a ğ‘‘-dimensional matrix into ğ‘š-dimensional hash codes. 
	- The time complexity of this operation is ğ‘‚ (ğ¿ğ‘šğ‘‘) and 
	- can be **reduced to ğ‘‚ (ğ¿ğ‘š log(ğ‘‘)) using the Approximating Random Projection algorithm**
	- è€Œä¸”==è¿˜å¯ä»¥ä¸å¬å›å¹¶è¡Œåšï¼Œåœ¨æ’åºå¼€å§‹ä¹‹å‰å°±å·²ç»å®Œæˆäº†==
