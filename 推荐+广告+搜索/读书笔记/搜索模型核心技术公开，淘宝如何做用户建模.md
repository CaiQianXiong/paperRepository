---
alias: AliSearch
发布时间: 2020-01-07
出品方: 阿里
价值: ⭐⭐⭐⭐
环节: 精排
---
关键词:: #Reco/用户行为序列 

---

# [搜索模型核心技术公开，淘宝如何做用户建模？](cubox://card?id=ff808081808322d701808cec261d665c)

- 基本方法：self-attention + attention pooling
	- self-attention: 刻画序列内部的相互关系
	- attention-pooling：匹配激活+aggregation

## 建模中短期序列
- ![[Pasted image 20220506145217.png | 500]]
- “鉴于用户历史行为非常丰富，而我们的序列长度有上限(L_max=50)，因此我们通过query的预测类目来甄选出与当前意图类目更相关的历史行为” -- <span style="color:aqua;font-weight:bold">类似sim的作法</span>
- 与sim不同的是，一次请求中query是唯一的，而不像candidate item那样有很多
- self-attention
	- 对attention结构进行了改造，用cosine代替了原来实现中的dot
- 用query对self-attention结果进行attention-pooling

## 建模长期序列
- 可以离线抽取近期特征，但是这样抽取出来的特征，无法结合当前的query信息
- 希望end-to-end的方式，根据当前query对长期历史进行建模

- 准备数据
	- 我们对两年的“成交行为”，按照季度划分成8个季度序列，每个季度序列是最大长度为N的子序列，确保每个季度的行为都能被保留
	- 只考虑“成交”，一来成交的信号更强，二来如果用别的行为，数据也太多了

- 先拿到短期序列的向量表达`shortseq_vec`
	- 标准的先self-attention，再拿query去做attention-pooling
	- ![[Pasted image 20220506150536.png | 500]]

- 再对长周期建模
	- 先每个季度内部self-attention
		- 这样做的另一个好处是降低耗时，毕竟self-attention的时间复杂度是$O(N^2)$（N是序列长度）
	- 再拿上一步得到的`shortseq_vec`对每个季度内部self-attention结果做attention-pooling
	- 最后对不同季度进行**concat(也尝试过atten_pooling，效果比concat稍微差一点)**，得到用户最终的长期偏好表达
	- ![[Pasted image 20220506151917.png | 500]]

## 结果分析

### Self Atten的作用
- 尝试去掉Self Atten层，对seq直接做Atten Pooling，AUC绝对值稳定降0.001。

- 我们理解Self Atten，从两个方面：
	- 如一般的解释，它确实对商品序列内部的依赖关系进行了建模，使得商品表达更为准确；
	- <span style="color:orange;font-weight:bold">在Self Atten过程中，用户最近行为的商品，作为用户意图最贴近的表示，作为Key，对整个序列进行了Atten，其得到的向量成为了在最后Atten Pooling中占比成份最大的信息</span>。💡👍
	- [[Curriculum Disentangled Recommendation with Noisy Multi-feedback#用target item和最近点击item衡量click权重 | 和微信作法中，用最后一个点击对其他点击历史做attention，有异曲同工之处]]

### 搜索中没有用Target Attention

- 搜索中用户主动输入的query，意图更强
- query只有一个，而candidate doc却数量众多